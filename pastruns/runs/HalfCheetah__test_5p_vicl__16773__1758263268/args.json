{
    "exp_name": "test_5p_vicl",
    "seed": 16773,
    "torch_deterministic": true,
    "cuda": true,
    "capture_video": false,
    "path": ".",
    "env_id": "HalfCheetah",
    "total_timesteps": 1000000,
    "buffer_size": 1000000,
    "gamma": 0.99,
    "tau": 0.005,
    "batch_size": 128,
    "learning_starts": 5000,
    "policy_lr": 0.0003,
    "q_lr": 0.001,
    "policy_frequency": 2,
    "target_network_frequency": 1,
    "alpha": 0.2,
    "autotune": true,
    "save_policy_checkpoints": 1000000,
    "act_deterministically": false,
    "interact_every": 1000,
    "llm_model": "meta-llama/Llama-3.2-1B",
    "method": "vicl",
    "dicl_pca_n_components": -1,
    "context_length": 500,
    "rescale_factor": 7.0,
    "up_shift": 1.5,
    "llm_learning_starts": 10000,
    "llm_learning_frequency": 256,
    "llm_batch_size": 7,
    "train_only_from_llm": false,
    "min_episodes_to_start_icl": 5,
    "burnin_llm": 0,
    "add_init_burin_steps_to_llm": false,
    "llm_percentage_to_keep": 100,
    "auxiliary_actions": true
}